{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivations related to Cross Entropy Loss (Binary and Categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Binary Cross Entropy Loss?\n",
    "\n",
    "Binary Cross Entropy Loss is defined as follows given our prediction vector y_{pred}$:\n",
    "\n",
    "$$ BCE = -\\sum_{i = 1}^{m}y^{(i)} \\cdot \\log(y_{pred}^{(i)}) + (1 - y^{(i)}) \\cdot \\log(1 - y_{pred}^{(i)}) $$\n",
    "\n",
    "I will go over each term one-by-one to explain the intuition.\n",
    "If the actual output $y^{(i)}$ is 1, then only the term $y^{(i)} \\cdot \\log(y_{pred}^{(i)})$ remains since $(1 - y^{(i)})$ results in 0. Then by taking the log of our probability output, a probability close to 0 will result in a value close to  $-\\infty$ where as a probability close to 1 will result in a value close to 0. Since we were meant to predict 1, we get a very large negative number the further away we are from 1. \n",
    "\n",
    "In the other case, when the output $y^{(i)}$ is 0, then only the term $(1 - y^{(i)}) \\cdot \\log(1 - y_{pred}^{(i)})$ remains. If our probability $y_{pred}^{(i)}$ was close to 1, then subtracting it from 1 results in a number close to 0. Then when we take the log of that number we get a value clsoe to $-\\infty$. However when our prediction was close to 0 (the true output), subtracting it from 1 results in a number close to 1, and taking the log of this results in a number close to 0. \n",
    "\n",
    "To summarize when we get the example very wrong, it results in a very large negative number, but when we get it close to being right it results in a small negative number. So if we sum it all up we get the total throughout all examples. Of course we typically think of minimizing loss functions (think of loss as positive) thus we negate the whole summation to make the entire term a positive number. Then, our goal will be to minimize this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding the BCE Formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the directory containing your code file to sys.path\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "\n",
    "from models.LogisticRegression import LogisticRegression\n",
    "\n",
    "# CREATE SOME DUMMY DATA\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = np.array([1 if el + 2*np.random.rand() else 0 for el in x])\n",
    "\n",
    "# reshape the data to place into the model\n",
    "X = np.reshape(x, (x.shape[0], 1))\n",
    "\n",
    "# initialize our model (I will use my Logistic Regression here)\n",
    "model = LogisticRegression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to find our predicted values $y_{pred}$ using our model (In this case Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54876573, 0.55214661, 0.55552267, 0.55889361, 0.56225914,\n",
       "       0.56561894, 0.56897273, 0.5723202 , 0.57566106, 0.57899502,\n",
       "       0.58232179, 0.58564109, 0.58895263, 0.59225613, 0.59555131,\n",
       "       0.5988379 , 0.60211563, 0.60538422, 0.60864341, 0.61189295])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to apply the formula above in code with our actual outputs $y$ and our predicted outputs $y_{pred}$.\n",
    "<br>\n",
    "It becomes quite simple with numpy, since we are able to take the element wise log of a numpy array as well as element wise multiply two numpy arrays and sum over them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss is: 10.886927818646447\n"
     ]
    }
   ],
   "source": [
    "def BCELoss(y, y_pred):\n",
    "    return -np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "\n",
    "print(f\"BCE Loss is: {BCELoss(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Binary Cross Entropy? (Digging into the theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *(Feel free to skip this math if you are not interested)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y^{(i)} \\in \\{0, 1\\}, \\: y_{pred}^{(i)} \\in [0, 1]$ be the actual output and predicted output for a given feature vector $x^{(i)} \\in \\mathbb{R}^{n}$ \n",
    "<br> Assume $P(y^{(i)} = 1 | x^{(i)}) = y_{pred}^{(i)}$. Then,\n",
    "    $$ \\implies P(y^{(i)} = 0 | x^{(i)}) = 1 - y_{pred}^{(i)} $$\n",
    "    $$ \\implies P(y^{(i)} | x^{(i)}) = (y_{pred}^{(i)})^{y^{(i)}} \\cdot (1 - y_{pred}^{(i)})^{1 - y^{(i)}} $$\n",
    "    $$ \\implies y^{(i)} | x^{(i)} \\sim Bernoulli(y_{pred}^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know that our output given our input follows a bernoulli distribution with the probability parameter $p$ as our predicted output.\n",
    "\n",
    "Let's define our predicted output as a function of our parameters for some fixed input. Rather than defining a hypothesis function of our input vector $x^{(i)}$, we define a function for a fixed x, and make our parameters the variable.\n",
    "\n",
    "Let $$g^{(i)}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R} \\\\ \\theta \\rightarrow y_{pred}^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the Likelihood as:\n",
    "\n",
    "$$ \\mathcal{L}(\\theta) = \\prod_{i = 1}^{m} P(y^{(i)} | x^{(i)}) $$\n",
    "\n",
    "By taking the log of the likelihood, we then get a summation:\n",
    "\n",
    "$$ \\log{\\mathcal{L}(\\theta)} = l(\\theta) = \\sum_{i=1}^{m}\\log((g^{(i)}(\\theta))^{y^{(i)}} \\cdot (1 - g^{(i)}(\\theta))^{1 - y^{(i)}}) $$\n",
    "\n",
    "$$ = \\sum_{i=1}^{m}\\log((g^{(i)}(\\theta))^{y^{(i)}}) + \\log((1 - g^{(i)}(\\theta))^{1 - y^{(i)}}) $$\n",
    "$$ = \\sum_{i=1}^{m}y^{(i)} \\cdot \\log(g^{(i)}(\\theta)) + (1 - y^{(i)}) \\cdot \\log(1 - g^{(i)}(\\theta)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use Maximum Likelihood Estimation to estimate our parameters $\\theta$\n",
    "\n",
    "$$ = \\underset{\\theta}{\\mathrm{argmax}} [\\sum_{i=1}^{m}y^{(i)} \\cdot \\log(g^{(i)}(\\theta)) + (1 - y^{(i)}) \\cdot \\log(1 - g^{(i)}(\\theta))] $$\n",
    "$$ = \\underset{\\theta}{\\mathrm{argmin}} [-\\sum_{i=1}^{m}y^{(i)} \\cdot \\log(g^{(i)}(\\theta)) + (1 - y^{(i)}) \\cdot \\log(1 - g^{(i)}(\\theta))] $$\n",
    "$$ = \\underset{\\theta}{\\mathrm{argmin}} [BCE] $$\n",
    "\n",
    "Which is clearly equivalent to minimizing the binary cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Derivative of BCE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform an optimization algorithm (such as gradient descent) we require the calculation of the partial derivates of a loss function with respect to the parameters of the model. \n",
    "\n",
    "So far, we have defined $y^{(i)}, g^{(i)}(\\theta), x^{(i)}$ to be the output, predicted output (as a function of our parameters) and our input vector respectively. In order to calculate the gradient of our loss function, we need to calculate the partial derivative w.r.t each of the parameters in the model. Lets first set our loss function to be a function of our parameters $J(\\theta) = BCE$. Then for some arbitrary parameter $\\theta_j$:\n",
    "\n",
    "$$ \\implies \\frac{\\partial J}{\\partial \\theta_{j}} = \\frac{\\partial}{\\partial \\theta_{j}}[-\\sum_{i=1}^{m}y^{(i)} \\cdot \\log(g^{(i)}(\\theta)) + (1 - y^{(i)}) \\cdot \\log(1 - g^{(i)}(\\theta))] $$\n",
    "\n",
    "$$ = -\\sum_{i=1}^{m}\\frac{\\partial}{\\partial \\theta_{j}}[y^{(i)} \\cdot \\log(g^{(i)}(\\theta)) + (1 - y^{(i)}) \\cdot \\log(1 - g^{(i)}(\\theta))] $$\n",
    "$$ = -\\sum_{i=1}^{m}y^{(i)}\\cdot \\frac{1}{g^{(i)}(\\theta)} \\cdot \\frac{\\partial g^{(i)}}{\\partial \\theta_{j}} + (1 - y^{(i)})\\cdot \\frac{1}{(1 - g^{(i)}(\\theta))} \\cdot (-\\frac{\\partial g^{(i)}}{\\partial \\theta_{j}})$$\n",
    "$$ = -\\sum_{i=1}^{m}\\frac{\\partial g^{(i)}}{\\partial \\theta_{j}} \\cdot (y^{(i)}\\cdot \\frac{1}{g^{(i)}(\\theta)} - (1 - y^{(i)})\\cdot \\frac{1}{(1 - g^{(i)}(\\theta))}) $$\n",
    "$$ = -\\sum_{i=1}^{m}\\frac{\\partial g^{(i)}}{\\partial \\theta_{j}} \\cdot (\\frac{y^{(i)}\\cdot (1 - g^{(i)}(\\theta)) - (1 - y^{(i)}) \\cdot g^{(i)}(\\theta)}{g^{(i)}(\\theta) \\cdot (1 - g^{(i)}(\\theta))}) $$\n",
    "$$ = -\\sum_{i=1}^{m}\\frac{\\partial g^{(i)}}{\\partial \\theta_{j}} \\cdot (\\frac{y^{(i)} - g^{(i)}(\\theta)}{g^{(i)}(\\theta) \\cdot (1 - g^{(i)}(\\theta))}) $$\n",
    "\n",
    "Now we can simplify this into a dot product of vectors since we are taking the sum of a product of elements. \n",
    "$$\\text{Let  } y = (y^{(1)}, y^{(2)}, ..., y^{(m)}) \\in \\mathbb{R}^{m} \\: \\text{  and  } \\: g(\\theta) = (g^{(1)}(\\theta), g^{(2)}(\\theta), ..., g^{(m)}(\\theta)) \\in \\mathbb{R}^{m} $$\n",
    "$$\\text{Let } \\frac{\\partial g}{\\partial \\theta_{j}} = (\\frac{\\partial g^{(1)}}{\\partial \\theta_{j}}, \\frac{\\partial g^{(2)}}{\\partial \\theta_{j}}, ..., \\frac{\\partial g^{(m)}}{\\partial \\theta_{j}}) \\in \\mathbb{R}^{m}$$\n",
    "\n",
    "Then we can express this as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J}{\\partial \\theta_{j}} = - \\frac{\\partial g}{\\partial \\theta_{j}}^T[(y - g(\\theta)) \\otimes (g(\\theta) - g(\\theta) \\odot g(\\theta))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\odot$ is the Hadamard product or element-wise multiplication and $\\otimes$ is the Hadamard division or element-wise division\n",
    "\n",
    "Let's refer to this set of Hadamard products and divisions as \n",
    "$y_{g} = (y - g(\\theta)) \\otimes (g(\\theta) - g(\\theta) \\odot g(\\theta)) \\in \\mathbb{R}^{m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have: $$ \\frac{\\partial J}{\\partial \\theta_{j}} = - \\frac{\\partial g}{\\partial \\theta_j}^T y_{g} $$\n",
    "\n",
    "Now to calculate the full gradient of the loss (which is a vector of all partial derivates) let us define the Jacobian matrix of $g$:\n",
    "$$\\text{Let } \\frac{\\partial g}{\\partial \\theta} = (\\frac{\\partial g}{\\partial \\theta_{1}} \\rightarrow \\frac{\\partial g}{\\partial \\theta_{n}}) \\in \\mathbb{R}^{m \\times n} $$\n",
    "\n",
    "Finally we have:\n",
    "\n",
    "$$ \\nabla_{J}(\\theta) = - \\frac{\\partial g}{\\partial \\theta}^T y_{g}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the directory containing your code file to sys.path\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "\n",
    "from models.LogisticRegression import LogisticRegression\n",
    "\n",
    "# CREATE SOME DUMMY DATA\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = np.array([1 if el + 2*np.random.rand() else 0 for el in x])\n",
    "\n",
    "# reshape the data to place into the model\n",
    "X = np.reshape(x, (x.shape[0], 1))\n",
    "\n",
    "# initialize our model (I will use my Logistic Regression here)\n",
    "model = LogisticRegression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After simplifying the calculation down to a matrix vector product, the coding becomes easy. We just have to code $-y_g$ and let our model calculate its own derivatives. Let's start by running a forward pass through our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65380716, 0.67051789, 0.68680838, 0.70265061, 0.7180205 ,\n",
       "       0.73289793, 0.7472667 , 0.76111445, 0.77443249, 0.78721562,\n",
       "       0.7994619 , 0.81117244, 0.8223511 , 0.83300421, 0.84314034,\n",
       "       0.85276998, 0.86190528, 0.87055979, 0.87874822, 0.88648618])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute $-y_g = (y - g(\\theta)) \\otimes (g(\\theta) - g(\\theta) \\odot g(\\theta)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.52950298, -1.49138453, -1.45601019, -1.42318242, -1.39271789,\n",
       "       -1.36444648, -1.3382103 , -1.31386284, -1.29126813, -1.2703    ,\n",
       "       -1.25084134, -1.2327835 , -1.21602562, -1.20047412, -1.18604217,\n",
       "       -1.17264916, -1.1602203 , -1.14868618, -1.1379824 , -1.12804917])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grads(y_pred, y):\n",
    "        return  (-1) * ((y - y_pred) / (y_pred - y_pred**2))\n",
    "\n",
    "loss_grads = grads(y_pred, y)\n",
    "loss_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to multiply by the Jacobian, but since the Jacobian is model specific, we pass our loss gradients into our model to fully compute the grads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-121.32886352,  -25.70463971])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_grads = model.grads(X, loss_grads)\n",
    "final_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we are left with a vector of gradients corresponding to each of the parameters of the model. We can then pass those gradients into an optimization algorithm such as stochastic gradient descent to apply them to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Categorical cross entropy can be derived in a similar pattern\n",
    "However rather than outputting a probability of just one class, we are outputting a probability distribution (vector) over $k$ classes. This means that we assume the output $y^{(i)}$ given $x^{(i)}$ follows a multinoulli distribution, which is an extension of the bernoulli distribution to multiple dimensions. If you follow a similar derivation function you should end up minimizing what is called the Categorical Cross Entropy Loss. The gradient of this loss also follows a similar process, however you end up with a matrix of derivates where each column is a class and each row a parameter (since each class has it's own hypothesis function)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
